{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza de arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "def corrigir_quebras(arquivo_entrada, arquivo_saida):\n",
    "    with open(arquivo_entrada, \"r\", encoding=\"utf-8\") as f_in, open(arquivo_saida, \"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
    "        leitor = csv.reader(f_in)\n",
    "        escritor = csv.writer(f_out)\n",
    "\n",
    "        linha_anterior = None\n",
    "\n",
    "        for linha in leitor:\n",
    "            if not linha:\n",
    "                continue  # Ignora linhas vazias\n",
    "\n",
    "            # Se a linha começa com \"/20\", ela deve ser unida à anterior\n",
    "            if linha[0].startswith(\"/20\") and linha_anterior:\n",
    "                # Remover colunas vazias no final da linha anterior\n",
    "                while linha_anterior and linha_anterior[-1] == \"\":\n",
    "                    linha_anterior.pop()\n",
    "\n",
    "                # Adicionar uma \",\" antes de concatenar \"/2024\"\n",
    "                linha_anterior[-1] += \", \" + linha[0]\n",
    "\n",
    "                # Adicionar o restante da linha quebrada\n",
    "                linha_anterior.extend(linha[1:])\n",
    "\n",
    "                continue  # Não escreve ainda, pois pode haver mais quebras\n",
    "\n",
    "            # Se a linha anterior já está corrigida, limpa as aspas e escreve no arquivo\n",
    "            if linha_anterior:\n",
    "                linha_anterior = [re.sub(r'\"', '', campo) for campo in linha_anterior]  # Remove aspas duplas\n",
    "                escritor.writerow(linha_anterior)\n",
    "\n",
    "            linha_anterior = linha  # Atualiza a linha anterior\n",
    "\n",
    "        # Escrever a última linha armazenada, se existir\n",
    "        if linha_anterior:\n",
    "            linha_anterior = [re.sub(r'\"', '', campo) for campo in linha_anterior]  # Remove aspas duplas\n",
    "            escritor.writerow(linha_anterior)\n",
    "\n",
    "def remover_linhas_vazias(arquivo_entrada, arquivo_saida):\n",
    "    \"\"\"Lê o arquivo final e remove linhas vazias\"\"\"\n",
    "    with open(arquivo_entrada, \"r\", encoding=\"utf-8\") as f_in, open(arquivo_saida, \"w\", encoding=\"utf-8\", newline=\"\") as f_out:\n",
    "        leitor = csv.reader(f_in)\n",
    "        escritor = csv.writer(f_out)\n",
    "\n",
    "        for linha in leitor:\n",
    "            linha = [re.sub(r'\"', '', campo) for campo in linha]  # Remove aspas duplas antes de salvar\n",
    "            if any(campo.strip() for campo in linha):  # Se a linha tiver pelo menos um campo preenchido\n",
    "                escritor.writerow(linha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tudo certo chefia\n"
     ]
    }
   ],
   "source": [
    "arq_original = 'AP_022024.csv'\n",
    "arq_meio = 'AP_022024_meio.csv'\n",
    "arq_final = 'AP_022024_limpo.csv'\n",
    "\n",
    "corrigir_quebras(arq_original, arq_meio)\n",
    "remover_linhas_vazias(arq_meio, arq_final)\n",
    "print('tudo certo chefia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m bases_limpos \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbases_limpos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(base_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "bases_limpos = os.path.join(base_dir, \"bases_limpos\")\n",
    "\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "os.makedirs(bases_limpos, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['NOME', 'ORGAO', 'CARGO', 'DATA_ADMISSAO','vazio','LOTACAO','CARGA_HORARIA', 'BRUTO', 'DECONTOS', 'LIQUIDO']\n",
    "df = pd.read_csv('AP_022024_limpo.csv', on_bad_lines='skip', encoding=\"utf-8\", sep=';', names=colunas)\n",
    "df = df.drop(\"vazio\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AP_022024.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
